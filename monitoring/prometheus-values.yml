# monitoring/prometheus-values.yml
# Helm values for kube-prometheus-stack

prometheus:
  prometheusSpec:
    retention: 30d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    
    additionalScrapeConfigs:
    - job_name: 'kubernetes-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__

alertmanager:
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'slack-notifications'
      routes:
      - match:
          severity: critical
        receiver: 'slack-critical'
        continue: true
      - match:
          severity: warning
        receiver: 'slack-notifications'
    
    receivers:
    - name: 'slack-notifications'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        title: 'Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    
    - name: 'slack-critical'
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#critical-alerts'
        title: 'ðŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

grafana:
  adminPassword: ${GRAFANA_ADMIN_PASSWORD}
  persistence:
    enabled: true
    storageClassName: gp3
    size: 10Gi
  
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-kube-prometheus-prometheus:9090
        access: proxy
        isDefault: true
  
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      kubernetes-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      node-exporter:
        gnetId: 1860
        revision: 27
        datasource: Prometheus
      kubernetes-pods:
        gnetId: 6417
        revision: 1
        datasource: Prometheus

---
# monitoring/servicemonitor.yml

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sample-microservice
  namespace: production
  labels:
    app: sample-microservice
spec:
  selector:
    matchLabels:
      app: sample-microservice
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
    scrapeTimeout: 10s

---
# monitoring/prometheusrule.yml

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sample-microservice-alerts
  namespace: production
  labels:
    app: sample-microservice
spec:
  groups:
  - name: sample-microservice
    interval: 30s
    rules:
    # High Error Rate
    - alert: HighErrorRate
      expr: |
        sum(rate(http_requests_total{status=~"5..", job="sample-microservice"}[5m])) 
        / 
        sum(rate(http_requests_total{job="sample-microservice"}[5m])) 
        > 0.05
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.job }}"
    
    # High Response Time
    - alert: HighResponseTime
      expr: |
        histogram_quantile(0.95, 
          sum(rate(http_request_duration_seconds_bucket{job="sample-microservice"}[5m])) by (le)
        ) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High response time detected"
        description: "95th percentile response time is {{ $value }}s for {{ $labels.job }}"
    
    # Pod Down
    - alert: PodDown
      expr: |
        kube_deployment_status_replicas_available{deployment="sample-microservice"} 
        < 
        kube_deployment_spec_replicas{deployment="sample-microservice"}
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Pod(s) down for sample-microservice"
        description: "{{ $value }} pod(s) are down for {{ $labels.deployment }}"
    
    # High Memory Usage
    - alert: HighMemoryUsage
      expr: |
        sum(container_memory_usage_bytes{pod=~"sample-microservice-.*"}) 
        / 
        sum(container_spec_memory_limit_bytes{pod=~"sample-microservice-.*"}) 
        > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage detected"
        description: "Memory usage is {{ $value | humanizePercentage }} for {{ $labels.pod }}"
    
    # High CPU Usage
    - alert: HighCPUUsage
      expr: |
        sum(rate(container_cpu_usage_seconds_total{pod=~"sample-microservice-.*"}[5m])) 
        / 
        sum(container_spec_cpu_quota{pod=~"sample-microservice-.*"}/container_spec_cpu_period{pod=~"sample-microservice-.*"}) 
        > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage detected"
        description: "CPU usage is {{ $value | humanizePercentage }} for {{ $labels.pod }}"
    
    # Container Restart
    - alert: ContainerRestart
      expr: |
        rate(kube_pod_container_status_restarts_total{pod=~"sample-microservice-.*"}[15m]) > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Container restarting"
        description: "Container {{ $labels.container }} in pod {{ $labels.pod }} is restarting"
